{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4VfkyVTDqgA"
   },
   "source": [
    "# **Specific Test IV. Diffusion Models**\n",
    "**Importing Libraries**\n",
    "*   os: For handling file paths.\n",
    "*   torch, torch.nn, torch.optim: PyTorch framework for building and training deep learning models.\n",
    "*   torch.utils.data: Handles dataset management (loading and batching).\n",
    "*   numpy: Used for numerical computations.\n",
    "*   sklearn.model_selection.train_test_split: Splits data into training and testing sets.\n",
    "*   ReduceLROnPlateau: A learning rate scheduler that reduces the learning rate if validation loss stops improving.\n",
    "*   torch.nn.functional as F: Provides additional neural network functions (like activation functions).\n",
    "*   json: Handles JSON file operations, possibly for storing model configurations or results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sr35tgFuCI8X"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbfAB_mHFo0a"
   },
   "source": [
    "# **SSIMLoss function**\n",
    "\n",
    "*  Inherits from nn.Module to create a custom loss function.\n",
    "\n",
    "*  Takes window_size (default: 11) and size_average as parameters.\n",
    "\n",
    "**Gaussian Window Function (gaussian_window)**\n",
    "\n",
    "*  Creates a 2D Gaussian kernel to smooth images before computing SSIM.\n",
    "\n",
    "*  Uses torch.exp(-(x - window_size // 2) ** 2 / (2 * sigma ** 2)) to generate the Gaussian distribution.\n",
    "\n",
    "*  The kernel is expanded across image channels for batch processing.\n",
    "\n",
    "**Forward Pass (forward)**\n",
    "\n",
    "*  Computes mean intensity (mu1, mu2) of both images using convolution with a Gaussian kernel.\n",
    "\n",
    "*  Computes variance (sigma1_sq, sigma2_sq) and covariance (sigma12).\n",
    "\n",
    "Applies the SSIM formula\n",
    "\n",
    "![Screenshot 2025-03-24 125918.png](data:image/png;base64,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)\n",
    "*  Returns 1 - SSIM to convert SSIM into a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQUK8UjeCI8X"
   },
   "outputs": [],
   "source": [
    "class SSIMLoss(nn.Module):\n",
    "    def __init__(self, window_size=11, size_average=True):\n",
    "        super(SSIMLoss, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def gaussian_window(self, channel, window_size, sigma=1.5):\n",
    "        x = torch.arange(window_size, dtype=torch.float32)\n",
    "        kernel = torch.exp(-(x - window_size // 2) ** 2 / (2 * sigma ** 2))\n",
    "        kernel = kernel / kernel.sum()\n",
    "\n",
    "        kernel_2d = kernel[:, None] * kernel[None, :]\n",
    "        kernel_2d = kernel_2d.expand(channel, 1, window_size, window_size)\n",
    "        return kernel_2d\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "        window = self.gaussian_window(channel, self.window_size).to(img1.device)\n",
    "\n",
    "        mu1 = F.conv2d(img1, window, padding=self.window_size//2, groups=channel)\n",
    "        mu2 = F.conv2d(img2, window, padding=self.window_size//2, groups=channel)\n",
    "\n",
    "        mu1_sq, mu2_sq, mu1_mu2 = mu1.pow(2), mu2.pow(2), mu1 * mu2\n",
    "\n",
    "        sigma1_sq = F.conv2d(img1 * img1, window, padding=self.window_size//2, groups=channel) - mu1_sq\n",
    "        sigma2_sq = F.conv2d(img2 * img2, window, padding=self.window_size//2, groups=channel) - mu2_sq\n",
    "        sigma12 = F.conv2d(img1 * img2, window, padding=self.window_size//2, groups=channel) - mu1_mu2\n",
    "\n",
    "        C1, C2 = 0.01**2, 0.03**2\n",
    "        ssim = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "        return 1 - ssim.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2w0p_VtQG3ZG"
   },
   "source": [
    "# **UNet architecture**\n",
    "\n",
    "*  Inherits from nn.Module to define a custom neural network.\n",
    "*  Implements an encoder-decoder architecture with a timestep embedding for time-dependent processing.\n",
    "\n",
    "Architecture Components.,\n",
    "\n",
    "**Timestep Embedding (self.time_embed)**\n",
    "*  A small fully connected network that maps a single timestep input (t) to a 1024-dimensional vector.\n",
    "*  Uses ReLU activation between two Linear layers.\n",
    "*  The final embedding is reshaped to match the spatial dimensions of the encoder output.\n",
    "\n",
    "**Encoder (self.encoder)**\n",
    "*  A series of convolutional layers that progressively increase the number of channels (64 → 128 → 256 → 512 → 1024).\n",
    "*  Uses Batch Normalization and ReLU activation after each convolution.\n",
    "\n",
    "**Decoder (self.decoder)**\n",
    "\n",
    "*  A series of convolutional layers that progressively reduce the number of channels (1024 → 512 → 256 → 128 → 64 → 32 → 1).\n",
    "\n",
    "*  Uses Batch Normalization and ReLU activation, except for the last layer.\n",
    "\n",
    "**Forward Pass (forward)**\n",
    "1. Timestep Processing\n",
    "\n",
    "*  The input timestep (t) is expanded, converted to float, and passed through self.time_embed.\n",
    "\n",
    "*  The output is reshaped to (batch, 1024, 1, 1) to be added later to the encoder output.\n",
    "\n",
    "2. Encoding\n",
    "\n",
    "* The input image (x) passes through the encoder layers, extracting hierarchical features.\n",
    "\n",
    "3. Adding Timestep Embedding\n",
    "\n",
    "* The encoded feature map is added to the timestep embedding to condition the network on time.\n",
    "\n",
    "4. Decoding\n",
    "\n",
    "* The combined feature map is passed through the decoder layers to reconstruct the output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhvkGHgiCI8Y"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        # Timestep embedding\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(1, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1024),\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.ModuleList([\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "        ])\n",
    "\n",
    "        self.decoder = nn.ModuleList([\n",
    "            nn.Conv2d(1024, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, kernel_size=3, padding=1),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t = t.unsqueeze(-1).float()\n",
    "        t_embed = self.time_embed(t)\n",
    "        t_embed = t_embed.view(-1, 1024, 1, 1)\n",
    "\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = x + t_embed\n",
    "\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuzb49O6IyPX"
   },
   "source": [
    "# **DDPM (Denoising Diffusion Probabilistic Model) Implementation**\n",
    "**Class Definition (DDPM)**\n",
    "\n",
    "*  Inherits from nn.Module to define a diffusion model.\n",
    "\n",
    "*  Implements noise-based training and sampling for image generation.\n",
    "\n",
    "**Main Components**\n",
    "1. Constructor (__init__)\n",
    "\n",
    "* Takes a model (e.g., U-Net) for noise prediction.\n",
    "\n",
    "* Defines 1000 timesteps for diffusion by default.\n",
    "\n",
    "*  Includes SSIMLoss and MSELoss for image similarity.\n",
    "\n",
    "*  Uses lambda_mse and lambda_ssim to balance the two loss terms.\n",
    "\n",
    "2. Loss Function (loss)\n",
    "\n",
    "* Adds random noise to the input image (x).\n",
    "\n",
    "* Uses the model to predict the added noise.\n",
    "\n",
    "* Computes MSE loss (difference between predicted and true noise).\n",
    "\n",
    "* Computes SSIM loss (structural similarity between denoised and original image).\n",
    "\n",
    "* Returns a weighted sum of MSE loss and SSIM loss.\n",
    "\n",
    "3. Forward Pass (forward): Calls the loss function to compute the loss for training.\n",
    "\n",
    "**Sampling Process (sample)**\n",
    "1. Initial Sampling\n",
    "\n",
    "* Starts with a random noise tensor (x).\n",
    "\n",
    "2. Reverse Diffusion (Loop over t)\n",
    "\n",
    "* Iterates backwards from timestep 999 → 0.\n",
    "\n",
    "* At each step:\n",
    "> * Uses model to predict noise.\n",
    "> * Computes denoised image estimate (x - predicted_noise).\n",
    "> * Computes SSIM loss gradient and updates x.\n",
    "> * Adds random noise proportional to the timestep (except at t=0).\n",
    "\n",
    "**Final Output**\n",
    "\n",
    "Returns the generated images after full denoising.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTR7UwkYCI8Y"
   },
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "    def __init__(self, model, timesteps=1000, lambda_mse=0.5, lambda_ssim=0.5):\n",
    "        super(DDPM, self).__init__()\n",
    "        self.model = model\n",
    "        self.timesteps = timesteps\n",
    "        self.ssim_loss = SSIMLoss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.lambda_mse = lambda_mse\n",
    "        self.lambda_ssim = lambda_ssim\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        noise = torch.randn_like(x)\n",
    "        noisy_x = x + noise\n",
    "        predicted_noise = self.model(noisy_x, t)\n",
    "\n",
    "        mse = self.mse_loss(predicted_noise, noise)\n",
    "        ssim = self.ssim_loss(noisy_x - predicted_noise, x)\n",
    "        total_loss = self.lambda_mse * mse + self.lambda_ssim * ssim\n",
    "        return total_loss\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        return self.loss(x, t)\n",
    "\n",
    "    def sample(self, num_samples=1, image_size=(64, 64), device=\"cpu\"):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((num_samples, 1, *image_size), device=device)\n",
    "\n",
    "            for t in range(self.timesteps - 1, -1, -1):\n",
    "                t_tensor = torch.full((num_samples,), t, device=device, dtype=torch.float32)\n",
    "                predicted_noise = self.model(x, t_tensor)\n",
    "                estimated_clean = x - predicted_noise\n",
    "                ssim_loss = self.ssim_loss(estimated_clean, x)\n",
    "                ssim_grad = torch.autograd.grad(ssim_loss.sum(), x)[0]\n",
    "                x = x - predicted_noise - self.lambda_ssim * ssim_grad\n",
    "\n",
    "                if t > 0:\n",
    "                    noise = torch.randn_like(x)\n",
    "                    x = x + noise * (1.0 - (t/self.timesteps))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdL0_o2vKf0i"
   },
   "source": [
    "# **LensingDataset Implementation**\n",
    "**Class Definition (LensingDataset)**\n",
    "\n",
    "*  Inherits from torch.utils.data.Dataset to create a custom dataset for gravitational lensing images.\n",
    "\n",
    "**Main Components**\n",
    "1. Constructor (__init__): Takes a list of file_paths pointing to .npy files containing image data.\n",
    "\n",
    "2. Dataset Length (__len__): Returns the total number of files in file_paths.\n",
    "\n",
    "3. Data Loading (__getitem__):\n",
    "\n",
    "* Loads .npy image data using np.load().\n",
    "\n",
    "* Converts it to a PyTorch tensor (torch.from_numpy(data).float()).\n",
    "\n",
    "* Ensures single-channel format by adding a dimension if needed (data.unsqueeze(0)).\n",
    "\n",
    "* Resizes the image to (64, 64) using bilinear interpolation.\n",
    "\n",
    "* Normalizes the image by subtracting the mean and dividing by the standard deviation ((data - mean) / (std + 1e-8)).\n",
    "\n",
    "* Returns the processed image tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkern8xmCI8Z"
   },
   "outputs": [],
   "source": [
    "class LensingDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.file_paths[idx])\n",
    "        data = torch.from_numpy(data).float()\n",
    "        if len(data.shape) == 2:\n",
    "            data = data.unsqueeze(0)\n",
    "        data = torch.nn.functional.interpolate(data.unsqueeze(0), size=(64, 64), mode='bilinear', align_corners=False).squeeze(0)\n",
    "        mean = data.mean()\n",
    "        std = data.std()\n",
    "        data = (data - mean) / (std + 1e-8)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC0oQR-HL-Mv"
   },
   "source": [
    "# **Model Training**\n",
    "**Function Definition (train)**\n",
    "\n",
    "* Trains a diffusion model using a dataset loaded via train_loader.\n",
    "\n",
    "* Uses Adam optimizer and ReduceLROnPlateau scheduler for adaptive learning rate adjustment.\n",
    "\n",
    "\n",
    "**Device Selection**: Uses GPU if available, otherwise defaults to CPU.\n",
    "\n",
    "**Model Setup**\n",
    "\n",
    "*  Moves the model to the selected device.\n",
    "\n",
    "*  Initializes Adam optimizer with a learning rate (lr=5e-5).\n",
    "\n",
    "*  Uses ReduceLROnPlateau to reduce learning rate if training loss plateaus.\n",
    "\n",
    "**Training Loop (epochs iterations)**\n",
    "\n",
    "* Sets model to training mode (model.train()).\n",
    "\n",
    "* Initializes training loss for tracking.\n",
    "\n",
    "* Iterates over mini-batches from train_loader:\n",
    "\n",
    "> * Moves the batch to the correct device.\n",
    "> * Resets gradients (optimizer.zero_grad()).\n",
    "> * Samples a random timestep t (between 0 and model.timesteps).\n",
    "> * Computes loss by passing batch and t to the model.\n",
    "> * Performs backpropagation (loss.backward()).\n",
    "> * Updates model parameters (optimizer.step()).\n",
    "> * Accumulates training loss.\n",
    "\n",
    "**Loss Calculation & Scheduler Update**\n",
    "\n",
    "* Computes average loss per epoch and prints it.\n",
    "\n",
    "* Adjusts the learning rate using scheduler.step(train_loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JeZpendHCI8Z"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs=25, lr=5e-5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            t = torch.randint(0, model.timesteps, (batch.shape[0],), dtype=torch.float32, device=device)\n",
    "            loss = model(batch, t)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {round(train_loss, 4)}\")\n",
    "        scheduler.step(train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCYBRcUyXhaF"
   },
   "source": [
    "\n",
    "\n",
    "1. Trains a DDPM (Denoising Diffusion Probabilistic Model) on a subset of the Lensing dataset.\n",
    "\n",
    "2. Saves trained model weights in JSON format for later use.\n",
    "\n",
    "3. Dataset Preparation\n",
    "\n",
    "> * Loads .npy image files from Samples/Samples/.\n",
    "> * Splits dataset into train (90%) and validation (10%) using train_test_split().\n",
    "> * Selects a random 0.5% subset of training data to speed up training.\n",
    "> * Creates a DataLoader with batch size = 32 and shuffling enabled.\n",
    "\n",
    "4. Model Initialization: Creates a DDPM model with a UNet backbone and 500 diffusion timesteps.\n",
    "\n",
    "5. Model Training\n",
    "\n",
    "> * Calls the train() function, training the model for 25 epochs.\n",
    ">*Training loss steadily decreases, indicating learning progress.\n",
    ">*Final loss drops from 1.0042 to 0.6779, showing effective training.\n",
    "\n",
    "6. Saving Model Weights\n",
    "\n",
    ">* Moves model to CPU before saving.\n",
    ">* Extracts model state dictionary (weights).\n",
    ">*Converts tensors into JSON-serializable format (lists, shapes, and data types).\n",
    ">* Saves weights to \"ddpm_model_weights.json\".\n",
    "\n",
    "**Training Observations**\n",
    "1. Smooth Loss Reduction: Loss decreases gradually from 1.0042 → 0.6779 over 25 epochs, showing effective model optimization.\n",
    "\n",
    "2. Future Improvements\n",
    ">* Increase training subset size for better generalization.\n",
    ">*Longer training (more epochs) may further enhance performance.\n",
    ">*Use validation loss monitoring to detect overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BjvMK3_BCI8a",
    "outputId": "063b55cc-27cb-4d56-8e80-26abe37a6756"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 1.0042\n",
      "Epoch 2/25, Train Loss: 0.9711\n",
      "Epoch 3/25, Train Loss: 0.9547\n",
      "Epoch 4/25, Train Loss: 0.9415\n",
      "Epoch 5/25, Train Loss: 0.9401\n",
      "Epoch 6/25, Train Loss: 0.931\n",
      "Epoch 7/25, Train Loss: 0.9311\n",
      "Epoch 8/25, Train Loss: 0.9244\n",
      "Epoch 9/25, Train Loss: 0.9231\n",
      "Epoch 10/25, Train Loss: 0.911\n",
      "Epoch 11/25, Train Loss: 0.9049\n",
      "Epoch 12/25, Train Loss: 0.8813\n",
      "Epoch 13/25, Train Loss: 0.8728\n",
      "Epoch 14/25, Train Loss: 0.8671\n",
      "Epoch 15/25, Train Loss: 0.8537\n",
      "Epoch 16/25, Train Loss: 0.8451\n",
      "Epoch 17/25, Train Loss: 0.8364\n",
      "Epoch 18/25, Train Loss: 0.7955\n",
      "Epoch 19/25, Train Loss: 0.7792\n",
      "Epoch 20/25, Train Loss: 0.7753\n",
      "Epoch 21/25, Train Loss: 0.7527\n",
      "Epoch 22/25, Train Loss: 0.7355\n",
      "Epoch 23/25, Train Loss: 0.7057\n",
      "Epoch 24/25, Train Loss: 0.7118\n",
      "Epoch 25/25, Train Loss: 0.6779\n",
      "Model weights saved to ddpm_model_weights.json\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data_dir = 'Samples/Samples'\n",
    "    file_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.npy')]\n",
    "    train_paths, val_paths = train_test_split(file_paths, test_size=0.1, random_state=42)\n",
    "    subset_size = int(0.05 * len(train_paths))\n",
    "    train_paths = np.random.choice(train_paths, subset_size, replace=False).tolist()\n",
    "    train_loader = DataLoader(LensingDataset(train_paths), batch_size=32, shuffle=True)\n",
    "    model = DDPM(UNet(), timesteps=500)\n",
    "    train(model, train_loader)\n",
    "   \n",
    "\n",
    "# Ensure model is in CPU mode for serialization\n",
    "    model = model.cpu()\n",
    "\n",
    "# Get the state dictionary (model weights)\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "# Convert tensors to lists for JSON serialization\n",
    "    state_dict_json = {\n",
    "    key: {\n",
    "        'data': value.cpu().numpy().tolist(),  # Convert to list\n",
    "        'shape': list(value.shape),           # Preserve original shape\n",
    "        'dtype': str(value.dtype)             # Preserve data type\n",
    "    }\n",
    "    for key, value in state_dict.items()\n",
    "}\n",
    "\n",
    "# Save to a JSON file\n",
    "    with open(\"ddpm_model_weights.json\", \"w\") as json_file:\n",
    "     json.dump(state_dict_json, json_file, indent=4)\n",
    "\n",
    "    print(\"Model weights saved to ddpm_model_weights.json\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
